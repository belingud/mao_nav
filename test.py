#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½ mock_data.js ä¸­æ‰€æœ‰ HTTP å›¾æ ‡åˆ° public/sitelogo ç›®å½•
"""

import os
import re
import json
import requests
import time
from urllib.parse import urlparse
from pathlib import Path
import sys
from bs4 import BeautifulSoup
from urllib.parse import urljoin


def extract_mock_data():
    """ä» mock_data.js æ–‡ä»¶ä¸­æå–æ•°æ®"""
    mock_file = "src/mock/mock_data.js"

    if not os.path.exists(mock_file):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {mock_file}")
        return None

    with open(mock_file, "r", encoding="utf-8") as f:
        content = f.read()

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– JSON æ•°æ®
    match = re.search(r"export const mockData = ({.*})", content, re.DOTALL)
    if not match:
        print("âŒ æ— æ³•è§£æ mock_data.js æ–‡ä»¶")
        return None

    try:
        # è§£æ JSON æ•°æ®
        data_str = match.group(1)
        data = json.loads(data_str)
        return data
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æé”™è¯¯: {e}")
        return None


def get_all_http_icons(data):
    """è·å–æ‰€æœ‰ HTTP åœ°å€çš„å›¾æ ‡"""
    http_icons = []

    for category in data.get("categories", []):
        for site in category.get("sites", []):
            icon_url = site.get("url", "")
            if icon_url.startswith("http"):
                # æå–åŸŸåä½œä¸ºæ–‡ä»¶å
                if "favicon/" in icon_url:
                    # ä» icon.maodeyu.fun/favicon/domain æå–åŸŸå
                    domain = icon_url.split("/favicon/")[-1]
                else:
                    # ä»æ™®é€šURLæå–åŸŸå
                    parsed = urlparse(site.get("url", ""))
                    domain = parsed.netloc

                http_icons.append(
                    {
                        "url": icon_url,
                        "domain": domain,
                        "filename": f"{domain}.ico",
                        "site_name": site.get("name", ""),
                        "site_url": site.get("url", ""),
                    }
                )

    return http_icons


def resolve_favicon_url(site_url, session):
    """
    å°è¯•è·å–ç½‘ç«™çš„ .ico æ ¼å¼ favicon åœ°å€ã€‚
    ä¼˜å…ˆä½¿ç”¨ /favicon.icoï¼Œå¦‚æœä¸æ˜¯ .ico æ ¼å¼åˆ™è§£æ HTMLã€‚
    è¿”å›: icon_url æˆ– None
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
        "Accept": "image/webp,image/apng,image/*,*/*;q=0.8",
    }

    parsed_url = urlparse(site_url)
    base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"

    # Step 1: å°è¯• /favicon.ico
    ico_url = f"{base_url}/favicon.ico"
    try:
        resp = session.get(ico_url, headers=headers, timeout=10)
        content_type = resp.headers.get("Content-Type", "")
        if (
            resp.ok
            and len(resp.content) >= 100
            and ("image/x-icon" in content_type or "image/vnd.microsoft.icon" in content_type)
        ):
            return ico_url
    except requests.RequestException:
        pass  # å¿½ç•¥ favicon.ico å¤±è´¥ï¼Œè¿›å…¥ä¸‹ä¸€æ­¥

    # Step 2: fallback è§£æ HTML ä¸­ <link rel=icon>
    try:
        html_resp = session.get(site_url, headers=headers, timeout=10)
        soup = BeautifulSoup(html_resp.text, "html.parser")

        for rel in ["icon", "shortcut icon", "apple-touch-icon"]:
            tag = soup.find("link", rel=rel)
            if tag and tag.get("href"):
                icon_url = urljoin(base_url, tag["href"])
                resp = session.get(icon_url, headers=headers, timeout=10)
                content_type = resp.headers.get("Content-Type", "")
                if (
                    resp.ok
                    and len(resp.content) >= 100
                    and ("image/x-icon" in content_type or "image/vnd.microsoft.icon" in content_type)
                ):
                    return icon_url
    except requests.RequestException:
        pass

    return None


def download_icon(icon_info, output_dir, session):
    """
    ä¸‹è½½å•ä¸ªå›¾æ ‡æ–‡ä»¶ï¼ˆåªä¸‹è½½ .ico æ ¼å¼ï¼‰
    å‚æ•°ï¼š
        icon_info: dictï¼ŒåŒ…å« 'url', 'filename', 'site_name'
        output_dir: pathlib.Path
        session: requests.Session å®ä¾‹
    """
    site_url = icon_info["url"]
    filename = icon_info["filename"]
    filepath = output_dir / filename

    if filepath.exists():
        print(f"â­ï¸  è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶: {filename}")
        return True

    print(f"ğŸ“¥ è·å–å›¾æ ‡: {icon_info['site_name']} ({filename})")

    try:
        icon_url = resolve_favicon_url(site_url, session)
        if not icon_url:
            print(f"âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ .ico å›¾æ ‡: {site_url}")
            return False

        resp = session.get(icon_url, stream=True, timeout=10)
        resp.raise_for_status()

        with open(filepath, "wb") as f:
            for chunk in resp.iter_content(1024):
                f.write(chunk)

        print(f"âœ… ä¸‹è½½æˆåŠŸ: {filename} ({len(resp.content)} bytes)")
        return True

    except requests.RequestException as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {filename} - {e}")
        return False
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {filename} - {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä¸‹è½½å›¾æ ‡...")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("public/sitelogo")
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir.absolute()}")

    # æå–æ•°æ®
    print("ğŸ“– è¯»å– mock_data.js...")
    data = extract_mock_data()
    if not data:
        return

    # è·å–æ‰€æœ‰HTTPå›¾æ ‡
    http_icons = get_all_http_icons(data)
    print(f"ğŸ” æ‰¾åˆ° {len(http_icons)} ä¸ª HTTP å›¾æ ‡")

    if not http_icons:
        print("âœ… æ²¡æœ‰éœ€è¦ä¸‹è½½çš„å›¾æ ‡")
        return

    # åˆ›å»ºä¼šè¯ä»¥å¤ç”¨è¿æ¥
    session = requests.Session()
    session.mount("http://", requests.adapters.HTTPAdapter(max_retries=3))
    session.mount("https://", requests.adapters.HTTPAdapter(max_retries=3))

    # ä¸‹è½½å›¾æ ‡
    success_count = 0
    failed_count = 0

    print(f"\nğŸ“¦ å¼€å§‹ä¸‹è½½ {len(http_icons)} ä¸ªå›¾æ ‡...\n")
    failed_urls = []

    for i, icon_info in enumerate(http_icons, 1):
        print(f"[{i}/{len(http_icons)}] ", end="")

        if download_icon(icon_info, output_dir, session):
            success_count += 1
        else:
            failed_count += 1
            failed_urls.append(icon_info["url"])

    # å…³é—­ä¼šè¯
    session.close()

    # è¾“å‡ºç»“æœ
    print("\nğŸ“Š ä¸‹è½½å®Œæˆ!")
    print(f"âœ… æˆåŠŸ: {success_count}")
    print(f"âŒ å¤±è´¥: {failed_count}")
    if failed_urls:
        print("âŒ å¤±è´¥çš„ URL:")
        for url in failed_urls:
            print(f"  - {url}")
    print(f"ğŸ“ æ–‡ä»¶ä¿å­˜åœ¨: {output_dir.absolute()}")

    # æ˜¾ç¤ºå·²ä¸‹è½½çš„æ–‡ä»¶
    downloaded_files = list(output_dir.glob("*.ico"))
    if downloaded_files:
        print(f"\nğŸ“‹ å·²ä¸‹è½½çš„æ–‡ä»¶ ({len(downloaded_files)} ä¸ª):")
        for file in sorted(downloaded_files):
            size = file.stat().st_size
            print(f"  - {file.name} ({size} bytes)")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")
        sys.exit(1)
