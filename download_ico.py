#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½ mock_data.js ä¸­æ‰€æœ‰ HTTP å›¾æ ‡åˆ° public/sitelogo ç›®å½•
"""

import json
import os
import re
import sys
from pathlib import Path
from typing import Dict, List, Optional
from urllib.parse import urljoin, urlparse

import httpx
from bs4 import BeautifulSoup
from PIL import Image
import io


# ==================== å¸¸é‡é…ç½® ====================
MOCK_DATA_FILE = "src/mock/mock_data.js"
OUTPUT_DIR = "public/sitelogo"
REQUEST_TIMEOUT = 10
MIN_ICON_SIZE = 100
MAX_RETRIES = 3

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Accept": "image/webp,image/apng,image/*,*/*;q=0.8",
}

ICON_CONTENT_TYPES = ["image/x-icon", "image/vnd.microsoft.icon"]
PNG_CONTENT_TYPES = ["image/png"]
FAVICON_RELS = ["icon", "shortcut icon", "apple-touch-icon"]


# ==================== æ•°æ®å¤„ç†æ¨¡å— ====================
def extract_mock_data() -> Optional[Dict]:
    """ä» mock_data.js æ–‡ä»¶ä¸­æå–æ•°æ®"""
    if not os.path.exists(MOCK_DATA_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {MOCK_DATA_FILE}")
        return None

    try:
        with open(MOCK_DATA_FILE, "r", encoding="utf-8") as f:
            content = f.read()

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– JSON æ•°æ®
        match = re.search(r"export const mockData = ({.*})", content, re.DOTALL)
        if not match:
            print("âŒ æ— æ³•è§£æ mock_data.js æ–‡ä»¶")
            return None

        data_str = match.group(1)
        return json.loads(data_str)
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æé”™è¯¯: {e}")
        return None
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶é”™è¯¯: {e}")
        return None


def get_all_http_icons(data: Dict) -> List[Dict]:
    """è·å–æ‰€æœ‰ HTTP åœ°å€çš„å›¾æ ‡ä¿¡æ¯"""
    http_icons = []

    for category in data.get("categories", []):
        for site in category.get("sites", []):
            icon_url = site.get("url", "")
            if not icon_url.startswith("http"):
                continue

            # æå–åŸŸåä½œä¸ºæ–‡ä»¶å
            if "favicon/" in icon_url:
                # ä» icon.maodeyu.fun/favicon/domain æå–åŸŸå
                domain = icon_url.split("/favicon/")[-1]
            else:
                # ä»æ™®é€šURLæå–åŸŸå
                parsed = urlparse(site.get("url", ""))
                domain = parsed.netloc

            http_icons.append(
                {
                    "url": icon_url,
                    "domain": domain,
                    "filename": f"{domain}.ico",
                    "site_name": site.get("name", ""),
                    "site_url": site.get("url", ""),
                }
            )

    return http_icons


# ==================== å›¾æ ‡è·å–æ¨¡å— ====================
def convert_png_to_ico(png_data: bytes) -> bytes:
    """å°†PNGæ•°æ®è½¬æ¢ä¸ºICOæ ¼å¼"""
    try:
        # ä»å­—èŠ‚æ•°æ®åˆ›å»ºPILå›¾åƒ
        png_image = Image.open(io.BytesIO(png_data))
        
        # è½¬æ¢ä¸ºRGBAæ¨¡å¼ï¼ˆæ”¯æŒé€æ˜åº¦ï¼‰
        if png_image.mode != 'RGBA':
            png_image = png_image.convert('RGBA')
        
        # åˆ›å»ºICOæ ¼å¼çš„å­—èŠ‚æµ
        ico_buffer = io.BytesIO()
        png_image.save(ico_buffer, format='ICO', sizes=[(32, 32)])
        ico_buffer.seek(0)
        
        return ico_buffer.getvalue()
    except Exception as e:
        print(f"âŒ PNGè½¬ICOå¤±è´¥: {e}")
        return b""
def _is_valid_icon_response(response: httpx.Response) -> bool:
    """æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å›¾æ ‡æ–‡ä»¶ï¼ˆICOæˆ–PNGï¼‰"""
    if not response.is_success or len(response.content) < MIN_ICON_SIZE:
        return False

    content_type = response.headers.get("Content-Type", "")
    # æ”¯æŒICOå’ŒPNGæ ¼å¼
    return (any(ico_type in content_type for ico_type in ICON_CONTENT_TYPES) or 
            any(png_type in content_type for png_type in PNG_CONTENT_TYPES))


def _try_favicon_ico(base_url: str, session: httpx.Client) -> Optional[str]:
    """å°è¯•è·å– /favicon.ico"""
    ico_url = f"{base_url}/favicon.ico"
    try:
        resp = session.get(ico_url, headers=HEADERS, timeout=REQUEST_TIMEOUT)
        if _is_valid_icon_response(resp):
            return ico_url
    except httpx.RequestError:
        pass
    return None


def _try_html_favicon(site_url: str, base_url: str, session: httpx.Client) -> Optional[str]:
    """ä» HTML ä¸­è§£æ favicon é“¾æ¥"""
    try:
        html_resp = session.get(site_url, headers=HEADERS, timeout=REQUEST_TIMEOUT)
        soup = BeautifulSoup(html_resp.text, "html.parser")

        for rel in FAVICON_RELS:
            tag = soup.find("link", rel=rel)
            if tag and tag.get("href"):
                icon_url = urljoin(base_url, tag["href"])
                resp = session.get(icon_url, headers=HEADERS, timeout=REQUEST_TIMEOUT)
                if _is_valid_icon_response(resp):
                    return icon_url
    except httpx.RequestError:
        pass
    return None


def resolve_favicon_url(site_url: str, session: httpx.Client) -> Optional[str]:
    """
    å°è¯•è·å–ç½‘ç«™çš„å›¾æ ‡åœ°å€ï¼ˆICO æˆ– PNGï¼‰
    ä¼˜å…ˆä½¿ç”¨ /favicon.icoï¼Œå¦‚æœæ‰¾ä¸åˆ°æˆ–æ— æ•ˆï¼Œåˆ™è§£æ HTML
    """
    parsed_url = urlparse(site_url)
    base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"

    # ä¼˜å…ˆå°è¯• /favicon.ico
    icon_url = _try_favicon_ico(base_url, session)
    if icon_url:
        return icon_url

    # å›é€€åˆ°è§£æ HTML
    return _try_html_favicon(site_url, base_url, session)


# ==================== ä¸‹è½½æ¨¡å— ====================
def download_icon(icon_info: Dict, output_dir: Path, session: httpx.Client) -> bool:
    """
    ä¸‹è½½å•ä¸ªå›¾æ ‡æ–‡ä»¶ï¼Œå¦‚æœæ˜¯PNGåˆ™è½¬æ¢ä¸ºICOæ ¼å¼
    """
    site_url = icon_info["url"]
    filename = icon_info["filename"]
    filepath = output_dir / filename

    if filepath.exists():
        print(f"â­ï¸  è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶: {filename}")
        return True

    print(f"ğŸ“¥ è·å–å›¾æ ‡: {icon_info['site_name']} ({filename})")

    try:
        icon_url = resolve_favicon_url(site_url, session)
        if not icon_url:
            print(f"âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å›¾æ ‡: {site_url}")
            return False

        resp = session.get(icon_url, headers=HEADERS, timeout=REQUEST_TIMEOUT)
        resp.raise_for_status()

        content_type = resp.headers.get("Content-Type", "")
        icon_data = resp.content

        # å¦‚æœæ˜¯PNGï¼Œåˆ™è½¬æ¢ä¸ºICO
        if any(png_type in content_type for png_type in PNG_CONTENT_TYPES):
            print("â„¹ï¸  æ£€æµ‹åˆ°PNGæ ¼å¼ï¼Œæ­£åœ¨è½¬æ¢ä¸ºICO...")
            icon_data = convert_png_to_ico(icon_data)
            if not icon_data:
                return False

        with open(filepath, "wb") as f:
            f.write(icon_data)

        print(f"âœ… ä¸‹è½½æˆåŠŸ: {filename} ({filepath.stat().st_size} bytes)")
        return True

    except httpx.RequestError as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {filename} - {e}")
        return False
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {filename} - {e}")
        return False


def _create_client() -> httpx.Client:
    """åˆ›å»ºé…ç½®å¥½çš„ httpx å®¢æˆ·ç«¯"""
    return httpx.Client(
        timeout=REQUEST_TIMEOUT,
        limits=httpx.Limits(max_connections=10, max_keepalive_connections=5),
    )


def _print_download_summary(
    success_count: int, failed_count: int, failed_urls: List[str], output_dir: Path
) -> None:
    """æ‰“å°ä¸‹è½½ç»“æœæ‘˜è¦"""
    print("\nğŸ“Š ä¸‹è½½å®Œæˆ!")
    print(f"âœ… æˆåŠŸ: {success_count}")
    print(f"âŒ å¤±è´¥: {failed_count}")

    if failed_urls:
        print("âŒ å¤±è´¥çš„ URL:")
        for url in failed_urls:
            print(f"  - {url}")

    print(f"ğŸ“ æ–‡ä»¶ä¿å­˜åœ¨: {output_dir.absolute()}")


# ==================== ä¸»ç¨‹åºæ¨¡å— ====================
def main() -> None:
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä¸‹è½½å›¾æ ‡...")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(OUTPUT_DIR)
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir.absolute()}")

    # æå–æ•°æ®
    print("ğŸ“– è¯»å– mock_data.js...")
    data = extract_mock_data()
    if not data:
        return

    # è·å–æ‰€æœ‰HTTPå›¾æ ‡
    http_icons = get_all_http_icons(data)
    print(f"ğŸ” æ‰¾åˆ° {len(http_icons)} ä¸ª HTTP å›¾æ ‡")

    if not http_icons:
        print("âœ… æ²¡æœ‰éœ€è¦ä¸‹è½½çš„å›¾æ ‡")
        return

    # åˆ›å»ºå®¢æˆ·ç«¯å¹¶ä¸‹è½½å›¾æ ‡
    success_count = 0
    failed_count = 0
    failed_urls = []

    print(f"\nğŸ“¦ å¼€å§‹ä¸‹è½½ {len(http_icons)} ä¸ªå›¾æ ‡...\n")

    with _create_client() as client:
        for i, icon_info in enumerate(http_icons, 1):
            print(f"[{i}/{len(http_icons)}] ", end="")

            if download_icon(icon_info, output_dir, client):
                success_count += 1
            else:
                failed_count += 1
                failed_urls.append(icon_info["url"])

    # è¾“å‡ºç»“æœæ‘˜è¦
    _print_download_summary(success_count, failed_count, failed_urls, output_dir)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")
        sys.exit(1)
